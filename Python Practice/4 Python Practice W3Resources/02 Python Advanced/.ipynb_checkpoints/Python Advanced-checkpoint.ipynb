{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e565c2c8-0314-4e0d-a439-a6f9369eb59d",
   "metadata": {},
   "source": [
    "# Write a Python program that implements a thread-safe priority queue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f9aff5ce-59e0-4802-861b-ea674b891039",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enqueued: Low Priority Task with priority 5\n",
      "Enqueued: High with priority 0\n",
      "Dequeued: High with priority 0\n",
      "Enqueued: Medium Priority Task with priority 2\n",
      "Enqueued: Medium with priority 3\n",
      "Enqueued: High Priority Task with priority 1\n",
      "Enqueued: Low with priority 7\n",
      "Enqueued: Urgent with priority 0\n",
      "Dequeued: Urgent with priority 0\n",
      "Dequeued: High Priority Task with priority 1\n",
      "Dequeued: Medium Priority Task with priority 2\n",
      "Dequeued: Medium with priority 3\n",
      "Dequeued: Low Priority Task with priority 5\n",
      "Dequeued: Low with priority 7\n",
      "All tasks processed.\n"
     ]
    }
   ],
   "source": [
    "import threading\n",
    "from queue import PriorityQueue\n",
    "import time\n",
    "\n",
    "# Define a thread-safe priority queue class\n",
    "class ThreadSafePriorityQueue:\n",
    "    def __init__(self):\n",
    "        # Use the built-in thread-safe PriorityQueue\n",
    "        self.queue = PriorityQueue()\n",
    "\n",
    "    def enqueue(self, priority, item):\n",
    "        self.queue.put((priority, item))\n",
    "        print(f\"Enqueued: {item} with priority {priority}\")\n",
    "\n",
    "    def dequeue(self):\n",
    "        if not self.queue.empty():\n",
    "            priority, item = self.queue.get()\n",
    "            print(f\"Dequeued: {item} with priority {priority}\")\n",
    "            return priority, item\n",
    "        else:\n",
    "            print(\"Queue is empty.\")\n",
    "            return None\n",
    "\n",
    "    def is_empty(self):\n",
    "        return self.queue.empty()\n",
    "\n",
    "# Example usage with multithreading\n",
    "def producer(queue, items):\n",
    "    for priority, item in items:\n",
    "        queue.enqueue(priority, item)\n",
    "        time.sleep(0.1)  # Simulate work\n",
    "\n",
    "def consumer(queue):\n",
    "    while not queue.is_empty():\n",
    "        queue.dequeue()\n",
    "        time.sleep(0.5)  # Simulate processing time\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Create a thread-safe priority queue\n",
    "    ts_queue = ThreadSafePriorityQueue()\n",
    "\n",
    "    # Define items to add to the queue (priority, item)\n",
    "    items_to_add = [\n",
    "        (5, \"Low Priority Task\"),\n",
    "        (2, \"Medium Priority Task\"),\n",
    "        (1, \"High Priority Task\"),   \n",
    "    ]\n",
    "\n",
    "    items = [\n",
    "        (0, \"High\"),\n",
    "        (3, \"Medium\"),\n",
    "        (7, \"Low\"),\n",
    "    ]\n",
    "\n",
    "    # Create threads for producer and consumer\n",
    "    producer_thread = threading.Thread(target=producer, args=(ts_queue, items_to_add))\n",
    "    producer_thread2 = threading.Thread(target=producer, args=(ts_queue, items))\n",
    "    consumer_thread = threading.Thread(target=consumer, args=(ts_queue,))\n",
    "\n",
    "    # Start threads\n",
    "    producer_thread.start()\n",
    "    producer_thread2.start()\n",
    "    consumer_thread.start()\n",
    "\n",
    "    # Wait for threads to finish\n",
    "    producer_thread.join()\n",
    "    ts_queue.enqueue(0, \"Urgent\")\n",
    "    consumer_thread.join()\n",
    "\n",
    "    print(\"All tasks processed.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "41be8618-7e3c-4edb-92cf-86f4c0e09609",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enqueued: Low Priority Task with priority 5\n",
      "Enqueued: High with priority 0\n",
      "Enqueued: Medium Priority Task with priority 2\n",
      "Dequeued: High with priority 0\n",
      "Enqueued: Medium with priority 3\n",
      "Enqueued: High Priority Task with priority 1\n",
      "Enqueued: Low with priority 7\n",
      "Enqueued: Urgent with priority 0\n",
      "Dequeued: Urgent with priority 0\n",
      "Dequeued: High Priority Task with priority 1\n",
      "Dequeued: Medium Priority Task with priority 2\n",
      "Dequeued: Medium with priority 3\n",
      "Dequeued: Low Priority Task with priority 5\n",
      "Dequeued: Low with priority 7\n",
      "All tasks processed.\n"
     ]
    }
   ],
   "source": [
    "import threading\n",
    "from queue import PriorityQueue\n",
    "import time\n",
    "\n",
    "# Define a thread-safe priority queue class\n",
    "class ThreadSafePriorityQueue:\n",
    "    def __init__(self):\n",
    "        # Use the built-in thread-safe PriorityQueue\n",
    "        self.queue = PriorityQueue()\n",
    "\n",
    "    def enqueue(self, priority, item):\n",
    "        self.queue.put((priority, item))\n",
    "        print(f\"Enqueued: {item} with priority {priority}\")\n",
    "\n",
    "    def dequeue(self):\n",
    "        if not self.queue.empty():\n",
    "            priority, item = self.queue.get()\n",
    "            print(f\"Dequeued: {item} with priority {priority}\")\n",
    "            return priority, item\n",
    "        else:\n",
    "            print(\"Queue is empty.\")\n",
    "            return None\n",
    "\n",
    "    def is_empty(self):\n",
    "        return self.queue.empty()\n",
    "\n",
    "# Example usage with multithreading\n",
    "def producer(queue, items):\n",
    "    for priority, item in items:\n",
    "        queue.enqueue(priority, item)\n",
    "        time.sleep(0.1)  # Simulate work\n",
    "\n",
    "def consumer(queue):\n",
    "    while not queue.is_empty():\n",
    "        queue.dequeue()\n",
    "        time.sleep(0.5)  # Simulate processing time\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Create a thread-safe priority queue\n",
    "    ts_queue = ThreadSafePriorityQueue()\n",
    "\n",
    "    # Define items to add to the queue (priority, item)\n",
    "    items_to_add = [\n",
    "        (5, \"Low Priority Task\"),\n",
    "        (2, \"Medium Priority Task\"),\n",
    "        (1, \"High Priority Task\"),   \n",
    "    ]\n",
    "\n",
    "    items = [\n",
    "        (0, \"High\"),\n",
    "        (3, \"Medium\"),\n",
    "        (7, \"Low\"),\n",
    "    ]\n",
    "\n",
    "    # Create threads for producer and consumer\n",
    "    producer_thread = threading.Thread(target=producer, args=(ts_queue, items_to_add))\n",
    "    producer_thread2 = threading.Thread(target=producer, args=(ts_queue, items))\n",
    "    consumer_thread = threading.Thread(target=consumer, args=(ts_queue,))\n",
    "\n",
    "    # Start threads\n",
    "    producer_thread.start()\n",
    "    producer_thread2.start()\n",
    "    consumer_thread.start()\n",
    "\n",
    "    # Wait for threads to finish\n",
    "    producer_thread.join()\n",
    "    ts_queue.enqueue(0, \"Urgent\")\n",
    "    producer_thread2.join()\n",
    "    consumer_thread.join()\n",
    "\n",
    "    print(\"All tasks processed.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4029b472-833d-4ab7-a3c8-a4d033806948",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enqueued: Low Priority Task with priority 5\n",
      "Enqueued: High with priority 0\n",
      "Dequeued: High with priority 0\n",
      "Enqueued: Medium Priority Task with priority 2\n",
      "Enqueued: Medium with priority 3\n",
      "Enqueued: High Priority Task with priority 1\n",
      "Enqueued: Low with priority 7\n",
      "Enqueued: Urgent with priority 0\n",
      "Dequeued: Urgent with priority 0\n",
      "Dequeued: High Priority Task with priority 1\n",
      "Dequeued: Medium Priority Task with priority 2\n",
      "Dequeued: Medium with priority 3\n",
      "Dequeued: Low Priority Task with priority 5\n",
      "Dequeued: Low with priority 7\n",
      "All tasks processed.\n"
     ]
    }
   ],
   "source": [
    "import threading\n",
    "from queue import PriorityQueue\n",
    "import time\n",
    "\n",
    "# Define a thread-safe priority queue class\n",
    "class ThreadSafePriorityQueue:\n",
    "    def __init__(self):\n",
    "        # Use the built-in thread-safe PriorityQueue\n",
    "        self.queue = PriorityQueue()\n",
    "\n",
    "    def enqueue(self, priority, item):\n",
    "        self.queue.put((priority, item))\n",
    "        print(f\"Enqueued: {item} with priority {priority}\")\n",
    "\n",
    "    def dequeue(self):\n",
    "        if not self.queue.empty():\n",
    "            priority, item = self.queue.get()\n",
    "            print(f\"Dequeued: {item} with priority {priority}\")\n",
    "            return priority, item\n",
    "        else:\n",
    "            print(\"Queue is empty.\")\n",
    "            return None\n",
    "\n",
    "    def is_empty(self):\n",
    "        return self.queue.empty()\n",
    "\n",
    "# Example usage with multithreading\n",
    "def producer(queue, items):\n",
    "    for priority, item in items:\n",
    "        queue.enqueue(priority, item)\n",
    "        time.sleep(0.1)  # Simulate work\n",
    "\n",
    "def consumer(queue):\n",
    "    while not queue.is_empty():\n",
    "        queue.dequeue()\n",
    "        time.sleep(0.5)  # Simulate processing time\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Create a thread-safe priority queue\n",
    "    ts_queue = ThreadSafePriorityQueue()\n",
    "\n",
    "    # Define items to add to the queue (priority, item)\n",
    "    items_to_add = [\n",
    "        (5, \"Low Priority Task\"),\n",
    "        (2, \"Medium Priority Task\"),\n",
    "        (1, \"High Priority Task\"),   \n",
    "    ]\n",
    "\n",
    "    items = [\n",
    "        (0, \"High\"),\n",
    "        (3, \"Medium\"),\n",
    "        (7, \"Low\"),\n",
    "    ]\n",
    "\n",
    "    # Create threads for producer and consumer\n",
    "    producer_thread = threading.Thread(target=producer, args=(ts_queue, items_to_add))\n",
    "    producer_thread2 = threading.Thread(target=producer, args=(ts_queue, items))\n",
    "    consumer_thread = threading.Thread(target=consumer, args=(ts_queue,))\n",
    "\n",
    "    # Start threads\n",
    "    producer_thread.start()\n",
    "    producer_thread2.start()\n",
    "    consumer_thread.start()\n",
    "\n",
    "    # Wait for threads to finish\n",
    "    producer_thread2.join()\n",
    "    producer_thread.join()\n",
    "    ts_queue.enqueue(0, \"Urgent\")\n",
    "    consumer_thread.join()\n",
    "\n",
    "    print(\"All tasks processed.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "458dc198-91a4-4242-ba56-df103ca206f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enqueued: Low Priority Task with priority 5\n",
      "Enqueued: High with priority 0\n",
      "Dequeued: High with priority 0\n",
      "All tasks processed.\n",
      "Enqueued: Medium Priority Task with priority 2\n",
      "Enqueued: Medium with priority 3\n",
      "Enqueued: High Priority Task with priority 1\n",
      "Enqueued: Low with priority 7\n",
      "Dequeued: High Priority Task with priority 1\n",
      "Dequeued: Medium Priority Task with priority 2\n",
      "Dequeued: Medium with priority 3\n",
      "Dequeued: Low Priority Task with priority 5\n",
      "Dequeued: Low with priority 7\n"
     ]
    }
   ],
   "source": [
    "import threading\n",
    "from queue import PriorityQueue\n",
    "import time\n",
    "\n",
    "# Define a thread-safe priority queue class\n",
    "class ThreadSafePriorityQueue:\n",
    "    def __init__(self):\n",
    "        # Use the built-in thread-safe PriorityQueue\n",
    "        self.queue = PriorityQueue()\n",
    "\n",
    "    def enqueue(self, priority, item):\n",
    "        self.queue.put((priority, item))\n",
    "        print(f\"Enqueued: {item} with priority {priority}\")\n",
    "\n",
    "    def dequeue(self):\n",
    "        if not self.queue.empty():\n",
    "            priority, item = self.queue.get()\n",
    "            print(f\"Dequeued: {item} with priority {priority}\")\n",
    "            return priority, item\n",
    "        else:\n",
    "            print(\"Queue is empty.\")\n",
    "            return None\n",
    "\n",
    "    def is_empty(self):\n",
    "        return self.queue.empty()\n",
    "\n",
    "# Example usage with multithreading\n",
    "def producer(queue, items):\n",
    "    for priority, item in items:\n",
    "        queue.enqueue(priority, item)\n",
    "        time.sleep(0.1)  # Simulate work\n",
    "\n",
    "def consumer(queue):\n",
    "    while not queue.is_empty():\n",
    "        queue.dequeue()\n",
    "        time.sleep(0.5)  # Simulate processing time\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Create a thread-safe priority queue\n",
    "    ts_queue = ThreadSafePriorityQueue()\n",
    "\n",
    "    # Define items to add to the queue (priority, item)\n",
    "    items_to_add = [\n",
    "        (5, \"Low Priority Task\"),\n",
    "        (2, \"Medium Priority Task\"),\n",
    "        (1, \"High Priority Task\"),   \n",
    "    ]\n",
    "\n",
    "    items = [\n",
    "        (0, \"High\"),\n",
    "        (3, \"Medium\"),\n",
    "        (7, \"Low\"),\n",
    "    ]\n",
    "\n",
    "    # Create threads for producer and consumer\n",
    "    producer_thread = threading.Thread(target=producer, args=(ts_queue, items_to_add))\n",
    "    producer_thread2 = threading.Thread(target=producer, args=(ts_queue, items))\n",
    "    consumer_thread = threading.Thread(target=consumer, args=(ts_queue,))\n",
    "\n",
    "    # Start threads\n",
    "    producer_thread.start()\n",
    "    producer_thread2.start()\n",
    "    consumer_thread.start()\n",
    "\n",
    "    # Wait for threads to finish\n",
    "    # producer_thread2.join()\n",
    "    # producer_thread.join()\n",
    "    # ts_queue.enqueue(0, \"Urgent\")\n",
    "    # consumer_thread.join()\n",
    "\n",
    "    print(\"All tasks processed.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2365f46e-186e-415d-9f12-b0fa4367afd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enqueued: Low Priority Task with priority 5\n",
      "Enqueued: High with priority 0\n",
      "Enqueued: Medium Priority Task with priority 2\n",
      "Enqueued: Medium with priority 3\n",
      "Enqueued: High Priority Task with priority 1\n",
      "Enqueued: Low with priority 7\n",
      "Dequeued: High with priority 0\n",
      "Enqueued: Urgent with priority 0\n",
      "Dequeued: Urgent with priority 0\n",
      "Dequeued: High Priority Task with priority 1\n",
      "Dequeued: Medium Priority Task with priority 2\n",
      "Dequeued: Medium with priority 3\n",
      "Dequeued: Low Priority Task with priority 5\n",
      "Dequeued: Low with priority 7\n",
      "All tasks processed.\n"
     ]
    }
   ],
   "source": [
    "import threading\n",
    "from queue import PriorityQueue\n",
    "import time\n",
    "\n",
    "# Define a thread-safe priority queue class\n",
    "class ThreadSafePriorityQueue:\n",
    "    def __init__(self):\n",
    "        # Use the built-in thread-safe PriorityQueue\n",
    "        self.queue = PriorityQueue()\n",
    "\n",
    "    def enqueue(self, priority, item):\n",
    "        self.queue.put((priority, item))\n",
    "        print(f\"Enqueued: {item} with priority {priority}\")\n",
    "\n",
    "    def dequeue(self):\n",
    "        if not self.queue.empty():\n",
    "            priority, item = self.queue.get()\n",
    "            print(f\"Dequeued: {item} with priority {priority}\")\n",
    "            return priority, item\n",
    "        else:\n",
    "            print(\"Queue is empty.\")\n",
    "            return None\n",
    "\n",
    "    def is_empty(self):\n",
    "        time.sleep(1)\n",
    "        return self.queue.empty()\n",
    "\n",
    "# Example usage with multithreading\n",
    "def producer(queue, items):\n",
    "    for priority, item in items:\n",
    "        queue.enqueue(priority, item)\n",
    "        time.sleep(0.5)  # Simulate work\n",
    "\n",
    "def consumer(queue):\n",
    "    while not queue.is_empty():\n",
    "        queue.dequeue()\n",
    "        time.sleep(0.1)  # Simulate processing time\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Create a thread-safe priority queue\n",
    "    ts_queue = ThreadSafePriorityQueue()\n",
    "\n",
    "    # Define items to add to the queue (priority, item)\n",
    "    items_to_add = [\n",
    "        (5, \"Low Priority Task\"),\n",
    "        (2, \"Medium Priority Task\"),\n",
    "        (1, \"High Priority Task\"),   \n",
    "    ]\n",
    "\n",
    "    items = [\n",
    "        (0, \"High\"),\n",
    "        (3, \"Medium\"),\n",
    "        (7, \"Low\"),\n",
    "    ]\n",
    "\n",
    "    # Create threads for producer and consumer\n",
    "    producer_thread = threading.Thread(target=producer, args=(ts_queue, items_to_add))\n",
    "    producer_thread2 = threading.Thread(target=producer, args=(ts_queue, items))\n",
    "    consumer_thread = threading.Thread(target=consumer, args=(ts_queue,))\n",
    "\n",
    "    # Start threads\n",
    "    producer_thread.start()\n",
    "    producer_thread2.start()\n",
    "    consumer_thread.start()\n",
    "\n",
    "    # Wait for threads to finish\n",
    "    producer_thread2.join()\n",
    "    producer_thread.join()\n",
    "    ts_queue.enqueue(0, \"Urgent\")\n",
    "    consumer_thread.join()\n",
    "\n",
    "    print(\"All tasks processed.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "bc793e59-3968-41a4-aa41-a54a969d87d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enqueued: High with priority 0\n",
      "Enqueued: Low Priority Task with priority 5\n",
      "Enqueued: Medium with priority 3\n",
      "Enqueued: Medium Priority Task with priority 2\n",
      "Enqueued: Low with priority 7\n",
      "Enqueued: High Priority Task with priority 1\n",
      "Enqueued: Urgent with priority 0\n",
      "Dequeued: High with priority 0\n",
      "Dequeued: Urgent with priority 0\n",
      "Dequeued: High Priority Task with priority 1\n",
      "Dequeued: Medium Priority Task with priority 2\n",
      "Dequeued: Medium with priority 3\n",
      "Dequeued: Low Priority Task with priority 5\n",
      "Dequeued: Low with priority 7\n",
      "All tasks processed.\n"
     ]
    }
   ],
   "source": [
    "import threading\n",
    "from queue import PriorityQueue\n",
    "import time\n",
    "\n",
    "# Define a thread-safe priority queue class\n",
    "class ThreadSafePriorityQueue:\n",
    "    def __init__(self):\n",
    "        # Use the built-in thread-safe PriorityQueue\n",
    "        self.queue = PriorityQueue()\n",
    "\n",
    "    def enqueue(self, priority, item):\n",
    "        self.queue.put((priority, item))\n",
    "        print(f\"Enqueued: {item} with priority {priority}\")\n",
    "\n",
    "    def dequeue(self):\n",
    "        if not self.queue.empty():\n",
    "            priority, item = self.queue.get()\n",
    "            print(f\"Dequeued: {item} with priority {priority}\")\n",
    "            return priority, item\n",
    "        else:\n",
    "            print(\"Queue is empty.\")\n",
    "            return None\n",
    "\n",
    "    def is_empty(self):\n",
    "        time.sleep(1)\n",
    "        return self.queue.empty()\n",
    "\n",
    "# Example usage with multithreading\n",
    "def producer(queue, items):\n",
    "    for priority, item in items:\n",
    "        queue.enqueue(priority, item)\n",
    "        time.sleep(0.1)  # Simulate work\n",
    "\n",
    "def consumer(queue):\n",
    "    while not queue.is_empty():\n",
    "        queue.dequeue()\n",
    "        time.sleep(0.2)  # Simulate processing time\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Create a thread-safe priority queue\n",
    "    ts_queue = ThreadSafePriorityQueue()\n",
    "\n",
    "    # Define items to add to the queue (priority, item)\n",
    "    items_to_add = [\n",
    "        (5, \"Low Priority Task\"),\n",
    "        (2, \"Medium Priority Task\"),\n",
    "        (1, \"High Priority Task\"),   \n",
    "    ]\n",
    "\n",
    "    items = [\n",
    "        (0, \"High\"),\n",
    "        (3, \"Medium\"),\n",
    "        (7, \"Low\"),\n",
    "    ]\n",
    "\n",
    "    # Create threads for producer and consumer\n",
    "    producer_thread = threading.Thread(target=producer, args=(ts_queue, items_to_add))\n",
    "    producer_thread2 = threading.Thread(target=producer, args=(ts_queue, items))\n",
    "    consumer_thread = threading.Thread(target=consumer, args=(ts_queue,))\n",
    "\n",
    "    # Start threads\n",
    "    producer_thread2.start()\n",
    "    producer_thread.start()\n",
    "    consumer_thread.start()\n",
    "\n",
    "    # Wait for threads to finish\n",
    "    producer_thread.join()\n",
    "    producer_thread2.join()\n",
    "    ts_queue.enqueue(0, \"Urgent\")\n",
    "    consumer_thread.join()\n",
    "\n",
    "    print(\"All tasks processed.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1da42a57-69f8-4023-9ad9-62aca2e634f6",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5128df4d-7f8f-41b1-92ad-f24eb1f282c6",
   "metadata": {},
   "source": [
    "# Write a Python program to implement a Multi-threaded Web Scraper that respects robots.txt rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2a64e6b9-3c12-46c7-984c-0ff332fc86b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import urllib.robotparser\n",
    "from urllib.parse import urlparse, urljoin "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "40f1d105-0972-444c-85b1-8264d8d92cd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://www.geeksforgeeks.org/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "d0f4a91c-0100-42db-acef-d4c9ce17980d",
   "metadata": {},
   "outputs": [],
   "source": [
    "parsed_url = urlparse(url)\n",
    "base_url = f'{parsed_url.scheme}://{parsed_url.netloc}'\n",
    "robots_url = urljoin(base_url, 'robots.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "33d197ff-aeb6-4fd8-8e5f-8b7b21f401af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://www.geeksforgeeks.org/robots.txt'"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "robots_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "3788b5bf-00f6-45dd-96b4-18475abbbfe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "rp = urllib.robotparser.RobotFileParser()\n",
    "rp.set_url(robots_url)\n",
    "# rp.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "dc946966-aae2-4228-a78f-a8c9215379d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_agent='*'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e82359a0-6803-43e9-88c8-a41e8ed92b63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rp.can_fetch(user_agent, url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "ed8ab5ab-16ee-4047-a387-e43164b10804",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting scraper for http://books.toscrape.com/\n",
      "Fetched data from http://books.toscrape.com/catalogue/page-3.html: \n",
      "    All products | Books to Scrape - Sandbox\n",
      "\n",
      "Fetched data from http://books.toscrape.com/catalogue/page-5.html: \n",
      "    All products | Books to Scrape - Sandbox\n",
      "\n",
      "Fetched data from http://books.toscrape.com/catalogue/page-2.html: \n",
      "    All products | Books to Scrape - Sandbox\n",
      "\n",
      "Fetched data from http://books.toscrape.com/catalogue/page-4.html: \n",
      "    All products | Books to Scrape - Sandbox\n",
      "\n",
      "Fetched data from http://books.toscrape.com/catalogue/page-1.html: \n",
      "    All products | Books to Scrape - Sandbox\n",
      "\n",
      "Fetched data from http://books.toscrape.com/catalogue/page-6.html: \n",
      "    All products | Books to Scrape - Sandbox\n",
      "\n",
      "\n",
      "Scraped Data:\n",
      "\n",
      "    All products | Books to Scrape - Sandbox\n",
      "\n",
      "\n",
      "    All products | Books to Scrape - Sandbox\n",
      "\n",
      "\n",
      "    All products | Books to Scrape - Sandbox\n",
      "\n",
      "\n",
      "    All products | Books to Scrape - Sandbox\n",
      "\n",
      "\n",
      "    All products | Books to Scrape - Sandbox\n",
      "\n",
      "\n",
      "    All products | Books to Scrape - Sandbox\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import time\n",
    "import re\n",
    "import threading\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib.robotparser import RobotFileParser\n",
    "\n",
    "# Function to parse robots.txt and return allowed URLs and crawl-delay\n",
    "def parse_robots_txt(base_url):\n",
    "    robots_url = f\"{base_url}/robots.txt\"\n",
    "    rp = RobotFileParser()\n",
    "    rp.set_url(robots_url)\n",
    "    rp.read()\n",
    "    return rp\n",
    "\n",
    "# Function to fetch and parse the web page\n",
    "def fetch_page(url, crawl_delay):\n",
    "    try:\n",
    "        # Respect the crawl delay between requests\n",
    "        time.sleep(crawl_delay)\n",
    "        \n",
    "        response = requests.get(url, timeout=10)\n",
    "        if response.status_code == 200:\n",
    "            soup = BeautifulSoup(response.content, 'html.parser')\n",
    "            title = soup.title.string if soup.title else \"No title\"\n",
    "            print(f\"Fetched data from {url}: {title}\")\n",
    "            return title  # Return relevant data (title in this case)\n",
    "        else:\n",
    "            print(f\"Failed to retrieve {url}. Status code: {response.status_code}\")\n",
    "            return None\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Error fetching {url}: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "# Function to handle scraping for multiple URLs\n",
    "def scrape_pages(urls, base_url):\n",
    "    rp = parse_robots_txt(base_url)\n",
    "    \n",
    "    # Crawl delay (default to 5 seconds if not specified in robots.txt)\n",
    "    crawl_delay = rp.crawl_delay('*') or 5  # You can adjust this value as needed\n",
    "\n",
    "    # List to hold results\n",
    "    results = []\n",
    "    \n",
    "    # Using ThreadPoolExecutor for multi-threading\n",
    "    with ThreadPoolExecutor(max_workers=5) as executor:\n",
    "        futures = {executor.submit(fetch_page, url, crawl_delay): url for url in urls}\n",
    "        for future in as_completed(futures):\n",
    "            result = future.result()\n",
    "            if result:\n",
    "                results.append(result)\n",
    "    return results\n",
    "\n",
    "# Main function to start the scraper\n",
    "def main():\n",
    "    base_url = \"http://books.toscrape.com/\" \n",
    "    urls_to_scrape = [\n",
    "        \"http://books.toscrape.com/catalogue/page-1.html\",\n",
    "        \"http://books.toscrape.com/catalogue/page-2.html\",\n",
    "        \"http://books.toscrape.com/catalogue/page-3.html\",\n",
    "        \"http://books.toscrape.com/catalogue/page-4.html\",\n",
    "        \"http://books.toscrape.com/catalogue/page-5.html\",\n",
    "        \"http://books.toscrape.com/catalogue/page-6.html\",\n",
    "    ]\n",
    "    \n",
    "    print(f\"Starting scraper for {base_url}\")\n",
    "    \n",
    "    # Scrape pages and get results\n",
    "    results = scrape_pages(urls_to_scrape, base_url)\n",
    "    \n",
    "    # Output the scraped results\n",
    "    print(\"\\nScraped Data:\")\n",
    "    for result in results:\n",
    "        print(result)\n",
    "\n",
    "# Run the scraper\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "566c99d0-541f-4575-affe-5d78bc0f9422",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully fetched http://books.toscrape.com/catalogue/page-1.html\n",
      "Successfully fetched http://books.toscrape.com/index.html\n",
      "Successfully fetched http://books.toscrape.com/catalogue/category/books_1/index.html\n",
      "Successfully fetched http://books.toscrape.com/catalogue/category/books/travel_2/index.html\n",
      "Successfully fetched http://books.toscrape.com/catalogue/category/books/mystery_3/index.html\n",
      "Successfully fetched http://books.toscrape.com/index.html\n",
      "Successfully fetched http://books.toscrape.com/catalogue/category/books/historical-fiction_4/index.html\n",
      "Successfully fetched http://books.toscrape.com/catalogue/category/books/sequential-art_5/index.html\n",
      "Successfully fetched http://books.toscrape.com/catalogue/category/books/romance_8/index.html\n",
      "Successfully fetched http://books.toscrape.com/catalogue/category/books/philosophy_7/index.html\n",
      "Successfully fetched http://books.toscrape.com/catalogue/category/books/classics_6/index.html\n",
      "Successfully fetched http://books.toscrape.com/catalogue/category/books/religion_12/index.html\n",
      "Successfully fetched http://books.toscrape.com/catalogue/category/books/womens-fiction_9/index.html\n",
      "Successfully fetched http://books.toscrape.com/catalogue/category/books/childrens_11/index.html\n",
      "Successfully fetched http://books.toscrape.com/catalogue/category/books/fiction_10/index.html\n",
      "Successfully fetched http://books.toscrape.com/catalogue/category/books/nonfiction_13/index.html\n",
      "Successfully fetched http://books.toscrape.com/catalogue/category/books/music_14/index.html\n",
      "Successfully fetched http://books.toscrape.com/catalogue/category/books/sports-and-games_17/index.html\n",
      "Successfully fetched http://books.toscrape.com/catalogue/category/books/default_15/index.html\n",
      "Successfully fetched http://books.toscrape.com/catalogue/category/books/science-fiction_16/index.html\n",
      "Successfully fetched http://books.toscrape.com/catalogue/category/books/add-a-comment_18/index.html\n",
      "Successfully fetched http://books.toscrape.com/catalogue/category/books/new-adult_20/index.html\n",
      "Successfully fetched http://books.toscrape.com/catalogue/category/books/fantasy_19/index.html\n",
      "Successfully fetched http://books.toscrape.com/catalogue/category/books/young-adult_21/index.html\n",
      "Successfully fetched http://books.toscrape.com/catalogue/category/books/science_22/index.html\n",
      "Successfully fetched http://books.toscrape.com/catalogue/category/books/poetry_23/index.html\n",
      "Successfully fetched http://books.toscrape.com/catalogue/category/books/paranormal_24/index.html\n",
      "Successfully fetched http://books.toscrape.com/catalogue/category/books/art_25/index.html\n",
      "Successfully fetched http://books.toscrape.com/catalogue/category/books/psychology_26/index.html\n",
      "Successfully fetched http://books.toscrape.com/catalogue/category/books/parenting_28/index.html\n",
      "Successfully fetched http://books.toscrape.com/catalogue/category/books/autobiography_27/index.html\n",
      "Successfully fetched http://books.toscrape.com/catalogue/category/books/adult-fiction_29/index.html\n",
      "Successfully fetched http://books.toscrape.com/catalogue/category/books/humor_30/index.html\n",
      "Successfully fetched http://books.toscrape.com/catalogue/category/books/horror_31/index.html\n",
      "Successfully fetched http://books.toscrape.com/catalogue/category/books/history_32/index.html\n",
      "Successfully fetched http://books.toscrape.com/catalogue/category/books/christian-fiction_34/index.html\n",
      "Successfully fetched http://books.toscrape.com/catalogue/category/books/food-and-drink_33/index.html\n",
      "Successfully fetched http://books.toscrape.com/catalogue/category/books/business_35/index.html\n",
      "Successfully fetched http://books.toscrape.com/catalogue/category/books/biography_36/index.html\n",
      "Successfully fetched http://books.toscrape.com/catalogue/category/books/contemporary_38/index.html\n",
      "Successfully fetched http://books.toscrape.com/catalogue/category/books/thriller_37/index.html\n",
      "Successfully fetched http://books.toscrape.com/catalogue/category/books/spirituality_39/index.html\n",
      "Successfully fetched http://books.toscrape.com/catalogue/category/books/academic_40/index.html\n",
      "Successfully fetched http://books.toscrape.com/catalogue/category/books/self-help_41/index.html\n",
      "Successfully fetched http://books.toscrape.com/catalogue/category/books/christian_43/index.html\n",
      "Successfully fetched http://books.toscrape.com/catalogue/category/books/historical_42/index.html\n",
      "Successfully fetched http://books.toscrape.com/catalogue/category/books/suspense_44/index.html\n",
      "Successfully fetched http://books.toscrape.com/catalogue/category/books/novels_46/index.html\n",
      "Successfully fetched http://books.toscrape.com/catalogue/category/books/politics_48/index.html\n",
      "Successfully fetched http://books.toscrape.com/catalogue/category/books/health_47/index.html\n",
      "Successfully fetched http://books.toscrape.com/catalogue/category/books/cultural_49/index.html\n",
      "Successfully fetched http://books.toscrape.com/catalogue/category/books/short-stories_45/index.html\n",
      "Successfully fetched http://books.toscrape.com/catalogue/category/books/erotica_50/index.html\n",
      "Successfully fetched http://books.toscrape.com/catalogue/category/books/crime_51/index.html\n",
      "Successfully fetched http://books.toscrape.com/catalogue/a-light-in-the-attic_1000/index.html\n",
      "Successfully fetched http://books.toscrape.com/catalogue/a-light-in-the-attic_1000/index.html\n",
      "Successfully fetched http://books.toscrape.com/catalogue/tipping-the-velvet_999/index.html\n",
      "Successfully fetched http://books.toscrape.com/catalogue/tipping-the-velvet_999/index.html\n",
      "Successfully fetched http://books.toscrape.com/catalogue/soumission_998/index.html\n",
      "Successfully fetched http://books.toscrape.com/catalogue/sharp-objects_997/index.html\n",
      "Successfully fetched http://books.toscrape.com/catalogue/soumission_998/index.html\n",
      "Successfully fetched http://books.toscrape.com/catalogue/sharp-objects_997/index.html\n",
      "Successfully fetched http://books.toscrape.com/catalogue/sapiens-a-brief-history-of-humankind_996/index.html\n",
      "Successfully fetched http://books.toscrape.com/catalogue/sapiens-a-brief-history-of-humankind_996/index.html\n",
      "Successfully fetched http://books.toscrape.com/catalogue/the-requiem-red_995/index.html\n",
      "Successfully fetched http://books.toscrape.com/catalogue/the-requiem-red_995/index.html\n",
      "Successfully fetched http://books.toscrape.com/catalogue/the-dirty-little-secrets-of-getting-your-dream-job_994/index.html\n",
      "Successfully fetched http://books.toscrape.com/catalogue/the-dirty-little-secrets-of-getting-your-dream-job_994/index.html\n",
      "Successfully fetched http://books.toscrape.com/catalogue/the-coming-woman-a-novel-based-on-the-life-of-the-infamous-feminist-victoria-woodhull_993/index.html\n",
      "Successfully fetched http://books.toscrape.com/catalogue/the-boys-in-the-boat-nine-americans-and-their-epic-quest-for-gold-at-the-1936-berlin-olympics_992/index.htmlSuccessfully fetched http://books.toscrape.com/catalogue/the-coming-woman-a-novel-based-on-the-life-of-the-infamous-feminist-victoria-woodhull_993/index.html\n",
      "\n",
      "Successfully fetched http://books.toscrape.com/catalogue/the-black-maria_991/index.html\n",
      "Successfully fetched http://books.toscrape.com/catalogue/the-boys-in-the-boat-nine-americans-and-their-epic-quest-for-gold-at-the-1936-berlin-olympics_992/index.html\n",
      "Successfully fetched http://books.toscrape.com/catalogue/the-black-maria_991/index.html\n",
      "Successfully fetched http://books.toscrape.com/catalogue/starving-hearts-triangular-trade-trilogy-1_990/index.html\n",
      "Successfully fetched http://books.toscrape.com/catalogue/starving-hearts-triangular-trade-trilogy-1_990/index.html\n",
      "Successfully fetched http://books.toscrape.com/catalogue/shakespeares-sonnets_989/index.html\n",
      "Successfully fetched http://books.toscrape.com/catalogue/shakespeares-sonnets_989/index.html\n",
      "Successfully fetched http://books.toscrape.com/catalogue/set-me-free_988/index.html\n",
      "Successfully fetched http://books.toscrape.com/catalogue/set-me-free_988/index.html\n",
      "Successfully fetched http://books.toscrape.com/catalogue/scott-pilgrims-precious-little-life-scott-pilgrim-1_987/index.html\n",
      "Successfully fetched http://books.toscrape.com/catalogue/rip-it-up-and-start-again_986/index.html\n",
      "Successfully fetched http://books.toscrape.com/catalogue/scott-pilgrims-precious-little-life-scott-pilgrim-1_987/index.html\n",
      "Successfully fetched http://books.toscrape.com/catalogue/rip-it-up-and-start-again_986/index.html\n",
      "Successfully fetched http://books.toscrape.com/catalogue/our-band-could-be-your-life-scenes-from-the-american-indie-underground-1981-1991_985/index.html\n",
      "Successfully fetched http://books.toscrape.com/catalogue/our-band-could-be-your-life-scenes-from-the-american-indie-underground-1981-1991_985/index.html\n",
      "Successfully fetched http://books.toscrape.com/catalogue/olio_984/index.html\n",
      "Successfully fetched http://books.toscrape.com/catalogue/olio_984/index.html\n",
      "Successfully fetched http://books.toscrape.com/catalogue/libertarianism-for-beginners_982/index.html\n",
      "Successfully fetched http://books.toscrape.com/catalogue/libertarianism-for-beginners_982/index.html\n",
      "Successfully fetched http://books.toscrape.com/catalogue/its-only-the-himalayas_981/index.html\n",
      "Successfully fetched http://books.toscrape.com/catalogue/mesaerion-the-best-science-fiction-stories-1800-1849_983/index.html\n",
      "Successfully fetched http://books.toscrape.com/catalogue/its-only-the-himalayas_981/index.html\n",
      "Successfully fetched http://books.toscrape.com/catalogue/mesaerion-the-best-science-fiction-stories-1800-1849_983/index.html\n",
      "Successfully fetched http://books.toscrape.com/catalogue/page-2.html\n",
      "Page title: \n",
      "    All products | Books to Scrape - Sandbox\n",
      "\n",
      "Page title: \n",
      "    All products | Books to Scrape - Sandbox\n",
      "\n",
      "Page title: \n",
      "    Books | \n",
      "     Books to Scrape - Sandbox\n",
      "\n",
      "\n",
      "Page title: \n",
      "    Travel | \n",
      "     Books to Scrape - Sandbox\n",
      "\n",
      "\n",
      "Page title: \n",
      "    Mystery | \n",
      "     Books to Scrape - Sandbox\n",
      "\n",
      "\n",
      "Page title: \n",
      "    Historical Fiction | \n",
      "     Books to Scrape - Sandbox\n",
      "\n",
      "\n",
      "Page title: \n",
      "    Sequential Art | \n",
      "     Books to Scrape - Sandbox\n",
      "\n",
      "\n",
      "Page title: \n",
      "    Classics | \n",
      "     Books to Scrape - Sandbox\n",
      "\n",
      "\n",
      "Page title: \n",
      "    Philosophy | \n",
      "     Books to Scrape - Sandbox\n",
      "\n",
      "\n",
      "Page title: \n",
      "    Romance | \n",
      "     Books to Scrape - Sandbox\n",
      "\n",
      "\n",
      "Page title: \n",
      "    Womens Fiction | \n",
      "     Books to Scrape - Sandbox\n",
      "\n",
      "\n",
      "Page title: \n",
      "    Fiction | \n",
      "     Books to Scrape - Sandbox\n",
      "\n",
      "\n",
      "Page title: \n",
      "    Childrens | \n",
      "     Books to Scrape - Sandbox\n",
      "\n",
      "\n",
      "Page title: \n",
      "    Religion | \n",
      "     Books to Scrape - Sandbox\n",
      "\n",
      "\n",
      "Page title: \n",
      "    Nonfiction | \n",
      "     Books to Scrape - Sandbox\n",
      "\n",
      "\n",
      "Page title: \n",
      "    Music | \n",
      "     Books to Scrape - Sandbox\n",
      "\n",
      "\n",
      "Page title: \n",
      "    Default | \n",
      "     Books to Scrape - Sandbox\n",
      "\n",
      "\n",
      "Page title: \n",
      "    Science Fiction | \n",
      "     Books to Scrape - Sandbox\n",
      "\n",
      "\n",
      "Page title: \n",
      "    Sports and Games | \n",
      "     Books to Scrape - Sandbox\n",
      "\n",
      "\n",
      "Page title: \n",
      "    Add a comment | \n",
      "     Books to Scrape - Sandbox\n",
      "\n",
      "\n",
      "Page title: \n",
      "    Fantasy | \n",
      "     Books to Scrape - Sandbox\n",
      "\n",
      "\n",
      "Page title: \n",
      "    New Adult | \n",
      "     Books to Scrape - Sandbox\n",
      "\n",
      "\n",
      "Page title: \n",
      "    Young Adult | \n",
      "     Books to Scrape - Sandbox\n",
      "\n",
      "\n",
      "Page title: \n",
      "    Science | \n",
      "     Books to Scrape - Sandbox\n",
      "\n",
      "\n",
      "Page title: \n",
      "    Poetry | \n",
      "     Books to Scrape - Sandbox\n",
      "\n",
      "\n",
      "Page title: \n",
      "    Paranormal | \n",
      "     Books to Scrape - Sandbox\n",
      "\n",
      "\n",
      "Page title: \n",
      "    Art | \n",
      "     Books to Scrape - Sandbox\n",
      "\n",
      "\n",
      "Page title: \n",
      "    Psychology | \n",
      "     Books to Scrape - Sandbox\n",
      "\n",
      "\n",
      "Page title: \n",
      "    Autobiography | \n",
      "     Books to Scrape - Sandbox\n",
      "\n",
      "\n",
      "Page title: \n",
      "    Parenting | \n",
      "     Books to Scrape - Sandbox\n",
      "\n",
      "\n",
      "Page title: \n",
      "    Adult Fiction | \n",
      "     Books to Scrape - Sandbox\n",
      "\n",
      "\n",
      "Page title: \n",
      "    Humor | \n",
      "     Books to Scrape - Sandbox\n",
      "\n",
      "\n",
      "Page title: \n",
      "    Horror | \n",
      "     Books to Scrape - Sandbox\n",
      "\n",
      "\n",
      "Page title: \n",
      "    History | \n",
      "     Books to Scrape - Sandbox\n",
      "\n",
      "\n",
      "Page title: \n",
      "    Food and Drink | \n",
      "     Books to Scrape - Sandbox\n",
      "\n",
      "\n",
      "Page title: \n",
      "    Christian Fiction | \n",
      "     Books to Scrape - Sandbox\n",
      "\n",
      "\n",
      "Page title: \n",
      "    Business | \n",
      "     Books to Scrape - Sandbox\n",
      "\n",
      "\n",
      "Page title: \n",
      "    Biography | \n",
      "     Books to Scrape - Sandbox\n",
      "\n",
      "\n",
      "Page title: \n",
      "    Thriller | \n",
      "     Books to Scrape - Sandbox\n",
      "\n",
      "\n",
      "Page title: \n",
      "    Contemporary | \n",
      "     Books to Scrape - Sandbox\n",
      "\n",
      "\n",
      "Page title: \n",
      "    Spirituality | \n",
      "     Books to Scrape - Sandbox\n",
      "\n",
      "\n",
      "Page title: \n",
      "    Academic | \n",
      "     Books to Scrape - Sandbox\n",
      "\n",
      "\n",
      "Page title: \n",
      "    Self Help | \n",
      "     Books to Scrape - Sandbox\n",
      "\n",
      "\n",
      "Page title: \n",
      "    Historical | \n",
      "     Books to Scrape - Sandbox\n",
      "\n",
      "\n",
      "Page title: \n",
      "    Christian | \n",
      "     Books to Scrape - Sandbox\n",
      "\n",
      "\n",
      "Page title: \n",
      "    Suspense | \n",
      "     Books to Scrape - Sandbox\n",
      "\n",
      "\n",
      "Page title: \n",
      "    Short Stories | \n",
      "     Books to Scrape - Sandbox\n",
      "\n",
      "\n",
      "Page title: \n",
      "    Novels | \n",
      "     Books to Scrape - Sandbox\n",
      "\n",
      "\n",
      "Page title: \n",
      "    Health | \n",
      "     Books to Scrape - Sandbox\n",
      "\n",
      "\n",
      "Page title: \n",
      "    Politics | \n",
      "     Books to Scrape - Sandbox\n",
      "\n",
      "\n",
      "Page title: \n",
      "    Cultural | \n",
      "     Books to Scrape - Sandbox\n",
      "\n",
      "\n",
      "Page title: \n",
      "    Erotica | \n",
      "     Books to Scrape - Sandbox\n",
      "\n",
      "\n",
      "Page title: \n",
      "    Crime | \n",
      "     Books to Scrape - Sandbox\n",
      "\n",
      "\n",
      "Page title: \n",
      "    A Light in the Attic | Books to Scrape - Sandbox\n",
      "\n",
      "Page title: \n",
      "    A Light in the Attic | Books to Scrape - Sandbox\n",
      "\n",
      "Page title: \n",
      "    Tipping the Velvet | Books to Scrape - Sandbox\n",
      "\n",
      "Page title: \n",
      "    Tipping the Velvet | Books to Scrape - Sandbox\n",
      "\n",
      "Page title: \n",
      "    Soumission | Books to Scrape - Sandbox\n",
      "\n",
      "Page title: \n",
      "    Soumission | Books to Scrape - Sandbox\n",
      "\n",
      "Page title: \n",
      "    Sharp Objects | Books to Scrape - Sandbox\n",
      "\n",
      "Page title: \n",
      "    Sharp Objects | Books to Scrape - Sandbox\n",
      "\n",
      "Page title: \n",
      "    Sapiens: A Brief History of Humankind | Books to Scrape - Sandbox\n",
      "\n",
      "Page title: \n",
      "    Sapiens: A Brief History of Humankind | Books to Scrape - Sandbox\n",
      "\n",
      "Page title: \n",
      "    The Requiem Red | Books to Scrape - Sandbox\n",
      "\n",
      "Page title: \n",
      "    The Requiem Red | Books to Scrape - Sandbox\n",
      "\n",
      "Page title: \n",
      "    The Dirty Little Secrets of Getting Your Dream Job | Books to Scrape - Sandbox\n",
      "\n",
      "Page title: \n",
      "    The Dirty Little Secrets of Getting Your Dream Job | Books to Scrape - Sandbox\n",
      "\n",
      "Page title: \n",
      "    The Coming Woman: A Novel Based on the Life of the Infamous Feminist, Victoria Woodhull | Books to Scrape - Sandbox\n",
      "\n",
      "Page title: \n",
      "    The Coming Woman: A Novel Based on the Life of the Infamous Feminist, Victoria Woodhull | Books to Scrape - Sandbox\n",
      "\n",
      "Page title: \n",
      "    The Boys in the Boat: Nine Americans and Their Epic Quest for Gold at the 1936 Berlin Olympics | Books to Scrape - Sandbox\n",
      "\n",
      "Page title: \n",
      "    The Boys in the Boat: Nine Americans and Their Epic Quest for Gold at the 1936 Berlin Olympics | Books to Scrape - Sandbox\n",
      "\n",
      "Page title: \n",
      "    The Black Maria | Books to Scrape - Sandbox\n",
      "\n",
      "Page title: \n",
      "    The Black Maria | Books to Scrape - Sandbox\n",
      "\n",
      "Page title: \n",
      "    Starving Hearts (Triangular Trade Trilogy, #1) | Books to Scrape - Sandbox\n",
      "\n",
      "Page title: \n",
      "    Starving Hearts (Triangular Trade Trilogy, #1) | Books to Scrape - Sandbox\n",
      "\n",
      "Page title: \n",
      "    Shakespeare's Sonnets | Books to Scrape - Sandbox\n",
      "\n",
      "Page title: \n",
      "    Shakespeare's Sonnets | Books to Scrape - Sandbox\n",
      "\n",
      "Page title: \n",
      "    Set Me Free | Books to Scrape - Sandbox\n",
      "\n",
      "Page title: \n",
      "    Set Me Free | Books to Scrape - Sandbox\n",
      "\n",
      "Page title: \n",
      "    Scott Pilgrim's Precious Little Life (Scott Pilgrim #1) | Books to Scrape - Sandbox\n",
      "\n",
      "Page title: \n",
      "    Scott Pilgrim's Precious Little Life (Scott Pilgrim #1) | Books to Scrape - Sandbox\n",
      "\n",
      "Page title: \n",
      "    Rip it Up and Start Again | Books to Scrape - Sandbox\n",
      "\n",
      "Page title: \n",
      "    Rip it Up and Start Again | Books to Scrape - Sandbox\n",
      "\n",
      "Page title: \n",
      "    Our Band Could Be Your Life: Scenes from the American Indie Underground, 1981-1991 | Books to Scrape - Sandbox\n",
      "\n",
      "Page title: \n",
      "    Our Band Could Be Your Life: Scenes from the American Indie Underground, 1981-1991 | Books to Scrape - Sandbox\n",
      "\n",
      "Page title: \n",
      "    Olio | Books to Scrape - Sandbox\n",
      "\n",
      "Page title: \n",
      "    Olio | Books to Scrape - Sandbox\n",
      "\n",
      "Page title: \n",
      "    Mesaerion: The Best Science Fiction Stories 1800-1849 | Books to Scrape - Sandbox\n",
      "\n",
      "Page title: \n",
      "    Mesaerion: The Best Science Fiction Stories 1800-1849 | Books to Scrape - Sandbox\n",
      "\n",
      "Page title: \n",
      "    Libertarianism for Beginners | Books to Scrape - Sandbox\n",
      "\n",
      "Page title: \n",
      "    Libertarianism for Beginners | Books to Scrape - Sandbox\n",
      "\n",
      "Page title: \n",
      "    It's Only the Himalayas | Books to Scrape - Sandbox\n",
      "\n",
      "Page title: \n",
      "    It's Only the Himalayas | Books to Scrape - Sandbox\n",
      "\n",
      "Page title: \n",
      "    All products | Books to Scrape - Sandbox\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import requests  # Import the requests module to handle HTTP requests\n",
    "from bs4 import BeautifulSoup  # Import BeautifulSoup for parsing HTML\n",
    "from concurrent.futures import ThreadPoolExecutor  # Import ThreadPoolExecutor for multi-threading\n",
    "import urllib.robotparser  # Import robotparser to handle robots.txt rules\n",
    "from urllib.parse import urlparse, urljoin  # Import urlparse and urljoin for URL manipulation\n",
    "\n",
    "# Function to check if a URL is allowed to be scraped according to robots.txt\n",
    "def is_allowed(url, user_agent='*'):\n",
    "    # Parse the URL to get the base URL\n",
    "    parsed_url = urlparse(url)\n",
    "    base_url = f'{parsed_url.scheme}://{parsed_url.netloc}'\n",
    "    robots_url = urljoin(base_url, 'robots.txt')\n",
    "    \n",
    "    # Parse robots.txt\n",
    "    rp = urllib.robotparser.RobotFileParser()\n",
    "    rp.set_url(robots_url)\n",
    "    rp.read()\n",
    "    \n",
    "    # Check if the URL is allowed to be accessed\n",
    "    return rp.can_fetch(user_agent, url)\n",
    "\n",
    "# Function to fetch and parse a webpage\n",
    "def fetch_page(url):\n",
    "    # Check if the URL is allowed to be scraped\n",
    "    if not is_allowed(url):\n",
    "        print(f'Scraping not allowed for {url}')\n",
    "        return None\n",
    "    \n",
    "    try:\n",
    "        # Send a GET request to the URL\n",
    "        response = requests.get(url)\n",
    "        # Check if the request was successful\n",
    "        if response.status_code == 200:\n",
    "            print(f'Successfully fetched {url}')\n",
    "            # Parse the HTML content of the page\n",
    "            soup = BeautifulSoup(response.content, 'html.parser')\n",
    "            return soup\n",
    "        else:\n",
    "            print(f'Failed to fetch {url} with status code {response.status_code}')\n",
    "    except Exception as e:\n",
    "        print(f'Exception occurred while fetching {url}: {e}')\n",
    "    return None\n",
    "\n",
    "# Function to extract all links from a webpage\n",
    "def extract_links(soup, base_url):\n",
    "    links = []\n",
    "    if soup:\n",
    "        # Find all anchor tags with href attribute\n",
    "        for link in soup.find_all('a', href=True):\n",
    "            # Resolve relative URLs\n",
    "            full_url = urljoin(base_url, link['href'])\n",
    "            links.append(full_url)\n",
    "    return links\n",
    "\n",
    "# Function to scrape a list of URLs using multiple threads\n",
    "def scrape_urls(urls, max_workers=5):\n",
    "    with ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
    "        # Submit fetch_page tasks to the ThreadPoolExecutor\n",
    "        futures = {executor.submit(fetch_page, url): url for url in urls}\n",
    "        results = []\n",
    "        for future in futures:\n",
    "            result = future.result()\n",
    "            if result:\n",
    "                results.append(result)\n",
    "        return results\n",
    "\n",
    "# Main function to start the web scraper\n",
    "def main():\n",
    "    start_url = \"http://books.toscrape.com/catalogue/page-1.html\"\n",
    "    soup = fetch_page(start_url)\n",
    "    if not soup:\n",
    "        return\n",
    "    \n",
    "    # Extract links from the start page\n",
    "    links = extract_links(soup, start_url)\n",
    "    # Scrape the extracted links\n",
    "    pages = scrape_urls(links)\n",
    "    \n",
    "    # Optionally, you can further process the scraped pages\n",
    "    for page in pages:\n",
    "        # Example: print the title of each page\n",
    "        if page:\n",
    "            title = page.find('title').get_text()\n",
    "            print(f'Page title: {title}')\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f51876d5-3fbc-48bf-b982-a22af7c7e80c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
